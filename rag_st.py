import os
import pandas as pd
import streamlit as st
from langchain.schema import Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# ä½¿ç”¨ç’°å¢ƒè®Šæ•¸
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("è«‹è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
    st.stop()

# åƒ¹æ ¼è³‡æ–™
PRICE_DICT = {
    "pricing": {
        "Wireless Keyboard": 40, "Wireless Mouse": 15, "USB-C Hub": 25, "Monitor Stand": 30,
        "Webcam": 50, "Laptop Cooler": 20, "External SSD": 100, "HDMI Cable": 10,
        "Desk Lamp": 35, "Ergonomic Chair": 150, "LED Monitor": 300, "Graphics Card": 400,
        "Mechanical Keyboard": 80, "Gaming Mouse": 45, "Soundbar": 60, "Network Router": 90,
        "Smart Speaker": 50, "Power Strip": 15, "USB Charger": 20, "Cooling Fan": 12
    }
}

@st.cache_data
def load_data():
    """è¼‰å…¥ Excel è³‡æ–™"""
    return pd.read_excel("./email_data.xlsx")

@st.cache_data
def create_documents(_df, price_dic=PRICE_DICT):
    """å»ºç«‹æ–‡ä»¶é›†åˆ"""
    documents = []
    # éƒµä»¶æ–‡ä»¶
    for _, row in _df.iterrows():
        documents.append(Document(
            page_content=row['body'],
            metadata={col: row[col] for col in _df.columns}
        ))
    
    # åƒ¹æ ¼æ–‡ä»¶
    price_content = (f"{str(price_dic)}\n\nç”¢å“åƒ¹æ ¼åˆ—è¡¨ï¼š\n" + 
                    "\n".join([f"{k}: {v}" for k, v in price_dic["pricing"].items()]))
    documents.append(Document(
        page_content=price_content,
        metadata={"type": "pricing"}
    ))
    return documents

@st.cache_resource
def init_vectordb(_documents):
    """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«"""
    embedding = OpenAIEmbeddings(
        model="text-embedding-3-large",
        openai_api_key=OPENAI_API_KEY
    )
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=200,
        chunk_overlap=20,
        separators=["\n\n", "\n", "(?<=ã€‚)", "(?<=ï¼)", "(?<=ï¼Ÿ)", ""]
    )
    chunks = text_splitter.split_documents(_documents)
    
    vectordb = Chroma.from_documents(
        documents=chunks,
        embedding=embedding,
        persist_directory="./chroma_db",
        collection_name="faq"
    )
    vectordb.persist()
    return vectordb

@st.cache_resource
def create_chain(_vectordb):
    """å»ºç«‹ QA éˆ"""
    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template="""
            ä½ æ˜¯ä¸€ä½éƒµä»¶æŸ¥è©¢å°ˆå®¶ã€‚ä½ çš„å·¥ä½œæ˜¯æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œåœ¨ context ä¸­æ‰¾åˆ°æœ€æ­£ç¢ºçš„å›ç­”ã€‚
            context ä¸­åŒ…å«çš„è³‡è¨Šï¼š
            1. ç”¢å“åƒ¹æ ¼ï¼šä½æ–¼ 'ç”¢å“åƒ¹æ ¼åˆ—è¡¨ï¼š' ä¹‹å¾Œ
            2. éŠ·å”®æ•¸é‡ï¼šä½æ–¼ "æ•¸é‡" æ¬„ä½
            3. ç”¢å“åç¨±ï¼šä½æ–¼ 'tables_json':"rows" ç¬¬1å€‹å€¼
            4. å¦‚æœæä¾›çš„äººåä¸å­˜åœ¨, è«‹ç›´æ¥å›ç­”"ä¸çŸ¥é“"

            Context: {context}
            Question: {question}
            è«‹æ ¹æ“šä¸Šè¿° context è©³ç´°å›ç­”å•é¡Œã€‚
        """
    )
    
    return RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model="gpt-4", temperature=0),
        retriever=_vectordb.as_retriever(
            search_kwargs={
                "fetch_k": 100,
                "k": 10,
                "mmr_score_cache": True,
                "mmr_rerank_top_k": 5
            },
            search_type="mmr"
        ),
        return_source_documents=True,
        chain_type="stuff",
        chain_type_kwargs={"prompt": prompt}
    )

class QA:
    def __init__(self, chain):
        self.chain = chain

    def query(self, prompt):
        try:
            result = self.chain(prompt)
            
            # æª¢ç´¢è³‡è¨Šæš«å­˜
            self.last_retrieval = {
                "doc_count": len(result['source_documents']),
                "documents": result['source_documents']
            }
            
            return result["result"]
        except Exception as e:
            st.error(f"æŸ¥è©¢éŒ¯èª¤ï¼š{str(e)}")
            return "ç³»çµ±ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"

def display_price_table():
    """é¡¯ç¤ºåƒ¹æ ¼è¡¨æ ¼"""
    st.sidebar.markdown("### ç”¢å“åƒ¹æ ¼è¡¨")
    
    # å°‡å­—å…¸è½‰æ›ç‚º DataFrame
    price_df = pd.DataFrame(
        list(PRICE_DICT["pricing"].items()),
        columns=["ç”¢å“åç¨±", "åƒ¹æ ¼ (USD)"]
    )
    
    # ä½¿ç”¨ Streamlit çš„è¡¨æ ¼åŠŸèƒ½é¡¯ç¤º
    st.sidebar.dataframe(
        price_df,
        column_config={
            "åƒ¹æ ¼ (USD)": st.column_config.NumberColumn(
                format="$%d",
                help="ç”¢å“åƒ¹æ ¼ï¼ˆç¾å…ƒï¼‰"
            )
        },
        hide_index=True,
        width=300
    )

def init_chat_interface(robot):
    """åˆå§‹åŒ–èŠå¤©ä»‹é¢"""
    st.title("Email(è¨‚å–®)æŸ¥è©¢æ©Ÿå™¨äºº")
    
    # é¡¯ç¤ºåƒ¹æ ¼è¡¨æ ¼
    display_price_table()
    
    # åœ¨å°è©±æ¡†ä¸Šæ–¹åŠ å…¥åˆ‡æ›æŒ‰éˆ•
    col1, col2 = st.columns([4, 1])
    with col2:
        # åŠ å…¥ CSS æ¨£å¼é¿å…æ–‡å­—æ›è¡Œ
        st.markdown("""
            <style>
            .stCheckbox > label {
                white-space: nowrap;
                overflow: hidden;
                text-overflow: ellipsis;
            }
            </style>
        """, unsafe_allow_html=True)
        show_retrieval = st.toggle('é¡¯ç¤ºæª¢ç´¢è³‡è¨Š', value=False, key="retrieval_toggle")
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # é¡¯ç¤ºå°è©±æ­·å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    if st.button("é¡¯ç¤ºç¯„ä¾‹å•é¡Œ"):
        st.info("ç¯„ä¾‹: å“ªå€‹ç”¢å“æœ€å¤šäººè²·?")
    
    # ä½¿ç”¨è€…è¼¸å…¥è™•ç†
    if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ..."):
        with st.chat_message("user"):
            st.write(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("assistant"):
            response = robot.query(prompt)
            st.write(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
            
            # é¡¯ç¤ºæª¢ç´¢è³‡è¨Šï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if show_retrieval and hasattr(robot, 'last_retrieval'):
                st.markdown("---")
                st.markdown("### ğŸ“š æª¢ç´¢è³‡è¨Š")
                st.write(f"æ‰¾åˆ° {robot.last_retrieval['doc_count']} ä»½ç›¸é—œæ–‡ä»¶")
                
                # ä½¿ç”¨ tabs æ›¿ä»£å·¢ç‹€ expander
                tabs = st.tabs([f"æ–‡ä»¶ {i+1}" for i in range(len(robot.last_retrieval['documents']))])
                for i, tab in enumerate(tabs):
                    with tab:
                        doc = robot.last_retrieval['documents'][i]
                        st.markdown("**æ–‡ä»¶å…§å®¹ï¼š**")
                        st.markdown(f"```\n{doc.page_content[:300]}...\n```")
                        if hasattr(doc, 'metadata') and doc.metadata:
                            st.markdown("**Metadataï¼š**")
                            st.json(doc.metadata)

def main():
    with st.spinner('ç³»çµ±åˆå§‹åŒ–ä¸­...'):
        df = load_data()
        documents = create_documents(df)
        vectordb = init_vectordb(documents)
        chain = create_chain(vectordb)
        robot = QA(chain)
    
    init_chat_interface(robot)

if __name__ == "__main__":
    main()


