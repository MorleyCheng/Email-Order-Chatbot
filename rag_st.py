"""RAG èŠå¤©æ©Ÿå™¨äººä¸»ç¨‹å¼"""
import os
import sys
import pysqlite3
sys.modules["sqlite3"] = pysqlite3
import pandas as pd
import streamlit as st
from langchain.schema import Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import openai
from pathlib import Path
from typing import Dict, Any
from openai import OpenAI, AuthenticationError, RateLimitError, APIConnectionError

def init_session_state():
    """åˆå§‹åŒ– session state"""
    if 'messages' not in st.session_state:  # å­˜å„²å°è©±æ­·å²
        st.session_state.messages = []
    if 'model_settings' not in st.session_state:  # å­˜å„²æ¨¡å‹è¨­å®š
        st.session_state.model_settings = DEFAULT_CONFIG.copy()
    if 'show_retrieval' not in st.session_state:  # å­˜å„² UI ç‹€æ…‹
        st.session_state.show_retrieval = False

def validate_api_key(api_key: str) -> bool:
    """é©—è­‰ OpenAI API Key"""
    try:
        # å»ºç«‹ OpenAI å®¢æˆ¶ç«¯ï¼Œç§»é™¤ä»£ç†è¨­å®š
        client = OpenAI(
            api_key=api_key,
            timeout=10.0  # è¨­å®šè¶…æ™‚æ™‚é–“
        )
        
        # æ¸¬è©¦å‘¼å« chat.completions API
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "system", "content": "ping"}],
            max_tokens=5  # é™åˆ¶å›æ‡‰é•·åº¦ä»¥åŠ å¿«é©—è­‰é€Ÿåº¦
        )
        
        if response:
            st.success("âœ… API Key é©—è­‰æˆåŠŸï¼")
            return True
    except AuthenticationError:
        st.error("âŒ API Key é©—è­‰å¤±æ•—ï¼šèªè­‰éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢º")
    except RateLimitError:
        st.error("âŒ API Key é©—è­‰å¤±æ•—ï¼šå·²è¶…éä½¿ç”¨é™åˆ¶ï¼Œè«‹æª¢æŸ¥å¸³æˆ¶é¡åº¦")
    except APIConnectionError:
        st.error("âŒ API Key é©—è­‰å¤±æ•—ï¼šç„¡æ³•é€£æ¥åˆ° OpenAI APIï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·š")
    except Exception as e:
        st.error(f"âŒ API Key é©—è­‰å¤±æ•—")
        #st.error(f"âŒ API Key é©—è­‰å¤±æ•—ï¼š{str(e)}")  #for debugging purposes
    return False

# åŸºæœ¬è¨­å®š
BASE_DIR = Path(__file__).parent
DATA_FILE = str(BASE_DIR / "email_data.xlsx")
CHROMA_DIR = str(BASE_DIR / "chroma_db")

# æ¨¡å‹é¸é …å’Œé™åˆ¶
MODEL_OPTIONS = {
    "embedding_models": ["text-embedding-3-large", "text-embedding-3-small", "text-embedding-ada-002"],
    "chat_models": ["o4-mini","gpt-4o"]
}

MODEL_CONSTRAINTS = {
    "o4-mini": {
        "temperature": {"min": 1.0, "max": 2.0}
    },
    "gpt-4o": {
        "temperature": {"min": 0.0, "max": 1.0}
    }
}

# é è¨­è¨­å®š
DEFAULT_CONFIG = {
    "openai": {
        "embedding_model": "text-embedding-3-large",
        "chat_model": "o4-mini",
        "temperature": 1.0
    },
    "vectordb": {
        "chunk_size": 200,
        "chunk_overlap": 20,
        "collection_name": "faq"
    },
    "retrieval": {
        "fetch_k": 100,
        "k": 30,
        "mmr_score_cache": True,
        "mmr_rerank_top_k": 5
    }
}

# åƒ¹æ ¼è³‡æ–™
PRICE_DICT = {
    "pricing": {
        "å¹»ç³–": 40, "ç”œèœœçˆ†å½ˆ": 15, "å½©è™¹å¥‡ç·£": 25, "å˜»å“ˆè·³è·³ç³–": 30,
        "æœˆå…‰å·§å…‹åŠ›çƒ": 50, "ç³–é›²": 20, "é­”æ³•èƒ½é‡ç³–": 100, "è“æœæ´¾å°æ£’æ£’ç³–": 10,
        "é©¢å­è»Ÿç³–": 35, "ç”œå…‰è¿·è¹¤": 150
    }
}

@st.cache_data
def load_data():
    """è¼‰å…¥ Excel è³‡æ–™"""
    try:
        return pd.read_excel(DATA_FILE)
    except Exception as e:
        st.error(f"è¼‰å…¥è³‡æ–™å¤±æ•—ï¼š{str(e)}")
        st.info(f"è«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘ï¼š{DATA_FILE}")
        st.stop()

@st.cache_data
def create_documents(_df, price_dic=PRICE_DICT):
    """å»ºç«‹æ–‡ä»¶é›†åˆ"""
    documents = []
    # éƒµä»¶æ–‡ä»¶
    for _, row in _df.iterrows():
        documents.append(Document(
            page_content=row['body'],
            metadata={col: row[col] for col in _df.columns}
        ))
    
    # åƒ¹æ ¼æ–‡ä»¶
    price_content = (f"{str(price_dic)}\n\nç”¢å“åƒ¹æ ¼åˆ—è¡¨ï¼š\n" + 
                    "\n".join([f"{k}: {v}" for k, v in price_dic["pricing"].items()]))
    documents.append(Document(
        page_content=price_content,
        metadata={"type": "pricing"}
    ))
    return documents

@st.cache_resource
def init_vectordb(_documents, config):
    """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«"""
    try:
        embedding = OpenAIEmbeddings(
            model=config["openai"]["embedding_model"],
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config["vectordb"]["chunk_size"],
            chunk_overlap=config["vectordb"]["chunk_overlap"],
            separators=["\n\n", "\n", "(?<=ã€‚)", "(?<=ï¼)", "(?<=ï¼Ÿ)", ""]
        )
        chunks = text_splitter.split_documents(_documents)
        
        vectordb = Chroma.from_documents(
            documents=chunks,
            embedding=embedding,
            persist_directory=CHROMA_DIR,
            collection_name=config["vectordb"]["collection_name"]
        )
        vectordb.persist()
        return vectordb
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å‘é‡è³‡æ–™åº«å¤±æ•—ï¼š{str(e)}")
        st.info(f"è«‹ç¢ºèªè³‡æ–™å¤¾æ¬Šé™ï¼š{CHROMA_DIR}")
        st.stop()

@st.cache_resource
def create_chain(_vectordb, config):
    """å»ºç«‹ QA éˆ"""
    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template="""
            ä½ æ˜¯ä¸€ä½éƒµä»¶æŸ¥è©¢å°ˆå®¶ã€‚ä½ çš„å·¥ä½œæ˜¯æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œåœ¨ context ä¸­æ‰¾åˆ°æœ€æ­£ç¢ºçš„å›ç­”ã€‚
            context ä¸­åŒ…å«çš„è³‡è¨Šï¼š
            1. ç”¢å“åƒ¹æ ¼ï¼šä½æ–¼ 'ç”¢å“åƒ¹æ ¼åˆ—è¡¨ï¼š' ä¹‹å¾Œ
            2. éŠ·å”®æ•¸é‡ï¼šä»¥jsonæ ¼å¼å„²å­˜åœ¨"tables_json"çš„rows[0][1] æ¬„ä½
            3. ç”¢å“åç¨±ï¼šä»¥å­—å…¸çš„å½¢å¼å„²å­˜åœ¨"tables_jsonçš„rows[0][0] æ¬„ä½
            4. å¦‚æœæä¾›çš„äººåä¸å­˜åœ¨, è«‹ç›´æ¥å›ç­”"ä¸çŸ¥é“"
            5. å¦‚æœä½¿ç”¨è€…è©¢å•"æŸäºº"çš„ç¸½å…±è³¼è²·åƒ¹æ ¼, è«‹æŠŠæ‰€æœ‰Hi "æŸäºº"é–‹é ­çš„è¨‚å–®æ˜ç´°è£¡çš„å°è¨ˆåŠ ç¸½å›ç­”


            Context: {context}
            Question: {question}
            è«‹æ ¹æ“šä¸Šè¿° context è©³ç´°å›ç­”å•é¡Œã€‚
        """
    )
    
    return RetrievalQA.from_chain_type(
        llm=ChatOpenAI(
            model=config["openai"]["chat_model"], 
            temperature=config["openai"]["temperature"],
            openai_api_key=os.getenv("OPENAI_API_KEY")
        ),
        retriever=_vectordb.as_retriever(
            search_kwargs=config["retrieval"],
            search_type="mmr"
        ),
        return_source_documents=True,
        chain_type="stuff",
        chain_type_kwargs={"prompt": prompt}
    )

class QA:
    def __init__(self, chain):
        self.chain = chain

    def query(self, prompt):
        try:
            result = self.chain(prompt)
            
            # æª¢ç´¢è³‡è¨Šæš«å­˜
            self.last_retrieval = {
                "doc_count": len(result['source_documents']),
                "documents": result['source_documents']
            }
            
            return result["result"]
        except Exception as e:
            st.error(f"æŸ¥è©¢éŒ¯èª¤ï¼š{str(e)}")
            return "ç³»çµ±ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"

def display_price_table():
    """é¡¯ç¤ºåƒ¹æ ¼è¡¨æ ¼"""
    st.sidebar.markdown("### ç”¢å“åƒ¹æ ¼è¡¨")
    
    # å°‡å­—å…¸è½‰æ›ç‚º DataFrame
    price_df = pd.DataFrame(
        list(PRICE_DICT["pricing"].items()),
        columns=["ç”¢å“åç¨±", "åƒ¹æ ¼ (TWD)"]
    )
    
    # ä½¿ç”¨ Streamlit çš„è¡¨æ ¼åŠŸèƒ½é¡¯ç¤º
    st.sidebar.dataframe(
        price_df,
        column_config={
            "åƒ¹æ ¼ (USD)": st.column_config.NumberColumn(
                format="$%d",
                help="ç”¢å“åƒ¹æ ¼ï¼ˆç¾å…ƒ) "
            )
        },
        hide_index=True,
        width=300
    )

def display_model_settings():
    """åœ¨å´é‚Šæ¬„é¡¯ç¤ºæ¨¡å‹åƒæ•¸è¨­å®š"""
    with st.sidebar:
        st.markdown("### ")
        with st.expander("## æ¨¡å‹åƒæ•¸è¨­å®š"):
            # OpenAI è¨­å®š
            st.markdown("### OpenAI è¨­å®š")
            st.session_state.model_settings["openai"]["embedding_model"] = st.selectbox(
                "Embedding æ¨¡å‹",
                options=MODEL_OPTIONS["embedding_models"],
                help="é¸æ“‡æ–‡å­—å‘é‡åŒ–æ¨¡å‹",
                key="embedding_model_select"
            )
            
            chat_model = st.selectbox(
                "Chat æ¨¡å‹",
                options=MODEL_OPTIONS["chat_models"],
                help="é¸æ“‡å°è©±æ¨¡å‹",
                key="chat_model_select"
            )
            st.session_state.model_settings["openai"]["chat_model"] = chat_model
            
            # æ ¹æ“šé¸æ“‡çš„æ¨¡å‹è¨­å®š temperature ç¯„åœ
            temp_min = MODEL_CONSTRAINTS[chat_model]["temperature"]["min"]
            temp_max = MODEL_CONSTRAINTS[chat_model]["temperature"]["max"]
            
            temperature = st.slider(
                "Temperature",
                min_value=temp_min,
                max_value=temp_max,
                value=max(temp_min, st.session_state.model_settings["openai"]["temperature"]),
                step=0.1,
                help=f"æ§åˆ¶å›ç­”çš„éš¨æ©Ÿæ€§ï¼ˆ{chat_model} æ¨¡å‹ç¯„åœï¼š{temp_min}-{temp_max}ï¼‰",
                key="temperature_slider"
            )
            st.session_state.model_settings["openai"]["temperature"] = temperature
            
            # å‘é‡è³‡æ–™åº«è¨­å®š
            st.markdown("### å‘é‡è³‡æ–™åº«è¨­å®š")
            st.session_state.model_settings["vectordb"]["chunk_size"] = st.number_input(
                "Chunk Size",
                min_value=100,
                max_value=1000,
                value=DEFAULT_CONFIG["vectordb"]["chunk_size"],
                step=50,
                help="æ–‡ä»¶åˆ†å‰²å¤§å°",
                key="chunk_size_input"
            )
            
            st.session_state.model_settings["vectordb"]["chunk_overlap"] = st.number_input(
                "Chunk Overlap",
                min_value=0,
                max_value=100,
                value=DEFAULT_CONFIG["vectordb"]["chunk_overlap"],
                step=10,
                help="æ–‡ä»¶åˆ†å‰²é‡ç–Šé•·åº¦",
                key="chunk_overlap_input"
            )
            
            # æª¢ç´¢è¨­å®š
            st.markdown("### æª¢ç´¢è¨­å®š")
            st.session_state.model_settings["retrieval"]["fetch_k"] = st.number_input(
                "Fetch K",
                min_value=10,
                max_value=500,
                value=DEFAULT_CONFIG["retrieval"]["fetch_k"],
                step=10,
                help="åˆå§‹æª¢ç´¢æ•¸é‡",
                key="fetch_k_input"
            )
            
            st.session_state.model_settings["retrieval"]["k"] = st.number_input(
                "K",
                min_value=1,
                max_value=50,
                value=DEFAULT_CONFIG["retrieval"]["k"],
                step=1,
                help="æœ€çµ‚è¿”å›æ–‡ä»¶æ•¸é‡",
                key="k_input"
            )
            
            # é¡¯ç¤ºé‡æ–°åˆå§‹åŒ–æŒ‰éˆ•
            if st.button("å¥—ç”¨è¨­å®š", key="apply_settings"):
                st.session_state.need_reinit = True
                st.info("è¨­å®šå·²æ›´æ–°ï¼Œç³»çµ±å°‡é‡æ–°åˆå§‹åŒ–...")
                st.rerun()


def get_openai_api_key():
    """å–å¾— OpenAI API Key"""
    with st.sidebar:
        # å…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–
        env_api_key = os.getenv("OPENAI_API_KEY", "")
        st.markdown("### ")
        api_key = st.text_input(
            "OpenAI API Key",
            type="password",
            placeholder="sk-...",
            help="è«‹è¼¸å…¥æ‚¨çš„ OpenAI API Key",
            value=env_api_key  # ä½¿ç”¨ç’°å¢ƒè®Šæ•¸çš„å€¼ä½œç‚ºé è¨­å€¼
        )
        
        if not api_key:
            st.warning("è«‹è¼¸å…¥ OpenAI API Key ä»¥ç¹¼çºŒä½¿ç”¨")
            st.stop()
        
        # æ·»åŠ åŸºæœ¬æ ¼å¼æª¢æŸ¥
        if not api_key.startswith('sk-'):
            st.error("API Key æ ¼å¼ä¸æ­£ç¢ºï¼Œæ‡‰è©²ä»¥ 'sk-' é–‹é ­")
            st.stop()
        
        # æª¢æŸ¥ API key æ˜¯å¦è®Šæ›´
        if 'previous_api_key' not in st.session_state or st.session_state.previous_api_key != api_key:
            # æ›´æ–°ç’°å¢ƒè®Šæ•¸
            os.environ["OPENAI_API_KEY"] = api_key
            
            # å¦‚æœæœ‰ .env æª”æ¡ˆï¼Œä¹Ÿæ›´æ–°å®ƒ
            env_path = Path(__file__).parent / '.env'
            try:
                if env_path.exists():
                    with open(env_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    # å°‹æ‰¾ä¸¦æ›´æ–° OPENAI_API_KEY
                    key_updated = False
                    for i, line in enumerate(lines):
                        if line.startswith('OPENAI_API_KEY='):
                            lines[i] = f'OPENAI_API_KEY={api_key}\n'
                            key_updated = True
                            break
                    
                    # å¦‚æœæ²’æœ‰æ‰¾åˆ°keyï¼Œå°±æ–°å¢ä¸€è¡Œ
                    if not key_updated:
                        lines.append(f'OPENAI_API_KEY={api_key}\n')
                    
                    # å¯«å›æª”æ¡ˆ
                    with open(env_path, 'w', encoding='utf-8') as f:
                        f.writelines(lines)
                else:
                    # å¦‚æœ .env æª”æ¡ˆä¸å­˜åœ¨ï¼Œå»ºç«‹æ–°æª”æ¡ˆ
                    with open(env_path, 'w', encoding='utf-8') as f:
                        f.write(f'OPENAI_API_KEY={api_key}\n')
            except Exception as e:
                st.warning(f"ç„¡æ³•æ›´æ–° .env æª”æ¡ˆï¼š{str(e)}")
            
            st.session_state.previous_api_key = api_key
            st.session_state.need_reinit = True  # è§¸ç™¼é‡æ–°åˆå§‹åŒ–
            st.rerun()  # é‡æ–°é‹è¡Œæ‡‰ç”¨
                   
        return api_key

class RAGBot:
    def __init__(self, api_key: str, config: Dict[str, Any]):
        self.api_key = api_key
        self.config = config
        self.setup_environment()
        self.init_components()
    
    def setup_environment(self):
        """è¨­å®šç’°å¢ƒ"""
        os.environ["OPENAI_API_KEY"] = self.api_key
        
    def init_components(self):
        """åˆå§‹åŒ–å…ƒä»¶"""
        with st.spinner('åˆå§‹åŒ–ä¸­...'):
            self.df = load_data()
            self.documents = create_documents(self.df)
            self.vectordb = init_vectordb(self.documents, self.config)
            self.chain = create_chain(self.vectordb, self.config)
            self.qa = QA(self.chain)

def main():
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_dotenv()
    
    # è¨­å®šé é¢
    st.set_page_config(
        page_title="Email(è¨‚å–®)æŸ¥è©¢æ©Ÿå™¨äºº",
        page_icon="ğŸ“§",
        layout="centered",
        initial_sidebar_state="expanded"
    )
    
    # è‡ªè¨‚ CSS æ¨£å¼
    st.markdown("""
        <style>
        /* å›ºå®šè¼¸å…¥å€åŸŸåœ¨åº•éƒ¨ */
        .stChatInputContainer {
            position: fixed !important;
            bottom: 0 !é‡è¦;
            background-color: white !é‡è¦;
            border-top: 1px solid #ddd !important;
            z-index: 99999 !é‡è¦;
            padding: 1rem !é‡è¦;
            left: 15.625rem !é‡è¦;  /* 250pxï¼Œé…åˆå´é‚Šæ¬„å¯¬åº¦ */
            right: 0 !é‡è¦;
        }
        
        /* ä¸»è¦å…§å®¹å€åŸŸåŠ ä¸Šåº•éƒ¨é‚Šè·ï¼Œé¿å…è¢«å›ºå®šè¼¸å…¥æ¡†é®æ“‹ */
        .main-content-area {
            margin-bottom: 6rem !é‡è¦;
            padding-bottom: 2rem !é‡è¦;
        }
        
        /* ç¢ºä¿æª¢ç´¢è³‡è¨Šå®¹å™¨ä¸æœƒè¢«è¼¸å…¥æ¡†é®æ“‹ */
        .retrieval-info {
            margin-bottom: 5rem !é‡è¦;
        }
        </style>
    """, unsafe_allow_html=True)
    
    try:
        init_session_state()
        if 'need_reinit' not in st.session_state:
            st.session_state.need_reinit = False
        
        # ä¸»è¦å…§å®¹å€åŸŸ
        #with st.container():
            #st.markdown('<div class="main-content-area">', unsafe_allow_html=True)
            
        # é¡¯ç¤ºæ¨™é¡Œå’Œèªªæ˜
        st.title("è¨‚å–®æŸ¥è©¢æ©Ÿå™¨äºº")
        st.caption("""
        é€™æ˜¯ä¸€å€‹åŸºæ–¼ RAG çš„æŸ¥è©¢ç³»çµ±, è³‡æ–™ä¾†æºæ˜¯å» å•†èˆ‡å®¢æˆ¶å¾€ä¾†çš„ email, å¯ä»¥ï¼š
        - æŸ¥è©¢ç”¢å“åƒ¹æ ¼
        - åˆ†æéŠ·å”®æ•¸æ“š
        - å›ç­”ç›¸é—œå•é¡Œ
        """)
        
        # å´é‚Šæ¬„è¨­å®š
        with st.sidebar:
            display_price_table()
            display_model_settings()
            api_key = get_openai_api_key()
            
            if not api_key or not validate_api_key(api_key):
                return
            
            # æª¢ç´¢è³‡è¨Šé–‹é—œ
            st.markdown("### ")
            st.session_state.show_retrieval = st.toggle(
                'é¡¯ç¤ºæª¢ç´¢è³‡è¨Š',
                value=st.session_state.show_retrieval,
                key="retrieval_toggle"
            )
        
        # åˆå§‹åŒ–æ©Ÿå™¨äºº
        if 'bot' not in st.session_state or st.session_state.need_reinit:
            bot = RAGBot(api_key, st.session_state.model_settings)
            st.session_state.bot = bot
            st.session_state.need_reinit = False
        else:
            bot = st.session_state.bot
        
        # é¡¯ç¤ºç¯„ä¾‹å•é¡Œ
        if st.button("é¡¯ç¤ºç¯„ä¾‹å•é¡Œ", key="example_button"):
            st.info("ç¯„ä¾‹: å“ªå€‹ç”¢å“æœ€å¤šäººè²·?")
        
        # é¡¯ç¤ºå°è©±æ­·å²
        for idx, message in enumerate(st.session_state.messages):
            with st.chat_message(message["role"]):
                st.write(message["content"])
                
                # åªåœ¨æœ€å¾Œä¸€æ¢åŠ©ç†æ¶ˆæ¯é¡¯ç¤ºæª¢ç´¢è³‡è¨Š
                if (message["role"] == "assistant" and 
                    idx == len(st.session_state.messages) - 1 and
                    st.session_state.show_retrieval and 
                    hasattr(bot.qa, 'last_retrieval')):
                    
                    with st.container():
                        st.markdown('<div class="retrieval-info">', unsafe_allow_html=True)
                        st.markdown("---")
                        st.markdown("### ğŸ“š æª¢ç´¢è³‡è¨Š")
                        st.write(f"æ‰¾åˆ° {bot.qa.last_retrieval['doc_count']} ä»½ç›¸é—œæ–‡ä»¶")
                        
                        tabs = st.tabs([f"æ–‡ä»¶ {i+1}" for i in range(len(bot.qa.last_retrieval['documents']))])
                        for i, tab in enumerate(tabs):
                            with tab:
                                doc = bot.qa.last_retrieval['documents'][i]
                                st.markdown("**æ–‡ä»¶å…§å®¹ï¼š**")
                                st.markdown(f"```\n{doc.page_content[:500]}...\n```")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # å›ºå®šè¼¸å…¥å€åŸŸ
        #with st.container():
            #st.markdown('<div class="stChatInputContainer">', unsafe_allow_html=True)
            
        # ä½¿ç”¨è€…è¼¸å…¥è™•ç†
        if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ..."):
            with st.chat_message("user"):
                st.write(prompt)
                st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("assistant"):
                response = bot.qa.query(prompt)
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                # é¡¯ç¤ºæª¢ç´¢è³‡è¨Šï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                if st.session_state.show_retrieval and hasattr(bot.qa, 'last_retrieval'):
                    with st.container():
                        st.markdown('<div class="retrieval-info">', unsafe_allow_html=True)
                        st.markdown("---")
                        st.markdown("### ğŸ“š æª¢ç´¢è³‡è¨Š")
                        st.write(f"æ‰¾åˆ° {bot.qa.last_retrieval['doc_count']} ä»½ç›¸é—œæ–‡ä»¶")
                        
                        tabs = st.tabs([f"æ–‡ä»¶ {i+1}" for i in range(len(bot.qa.last_retrieval['documents']))])
                        for i, tab in enumerate(tabs):
                            with tab:
                                doc = bot.qa.last_retrieval['documents'][i]
                                st.markdown("**æ–‡ä»¶å…§å®¹ï¼š**")
                                st.markdown(f"```\n{doc.page_content[:500]}...\n```")
            
            #st.markdown('</div>', unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"ç³»çµ±éŒ¯èª¤ï¼š{str(e)}")
        st.info("è«‹é‡æ–°æ•´ç†é é¢æˆ–è¯ç¹«ç³»çµ±ç®¡ç†å“¡")

if __name__ == "__main__":
    main()


